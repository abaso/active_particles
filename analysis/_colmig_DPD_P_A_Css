#! /home/yketa/miniconda3/bin/python3.6

import os
import sys

import math

import gsd
import gsd.hoomd
import gsd.pygsd

import numpy as np

import pickle

import operator

sys.path.append('/home/yketa')
from exponents import float_to_letters
sys.path.append('/home/yketa/hoomd/colmig_DPD_P_A/data')
from readdat import *

from collections import OrderedDict

from datetime import datetime
startTime = datetime.now()

data_dir = os.environ['DATA_DIRECTORY'] if 'DATA_DIRECTORY' in os.environ else os.getcwd() # data directory

wrap_file_name = os.environ['WRAPPED_FILE'] if 'WRAPPED_FILE' in os.environ else data_dir + '/trajectory.gsd' # wrapped trajectory file (.gsd)
unwrap_file_name = os.environ['UNWRAPPED_FILE'] if 'UNWRAPPED_FILE' in os.environ else data_dir + '/trajectory.dat' # unwrapped trajectory file (binary)
parameters_file = os.environ['PARAMETERS_FILE'] if 'PARAMETERS_FILE' in os.environ else data_dir + '/param.pickle' # parameters file

dis_time = int(eval(os.environ['TIME'])) if 'TIME' in os.environ else -1 # time interval for the displacement

init_frame = int(eval(os.environ['INITIAL_FRAME'])) if 'INITIAL_FRAME' in os.environ else -1 # initial time for the calculation of the displacement correlation
int_max = int(eval(os.environ['INTERVAL_MAXIMUM'])) if 'INTERVAL_MAXIMUM' in os.environ else 1 # maximum number of intervals taken for the calculation of the displacement correlation

r_max = float(eval(os.environ['R_MAX'])) if 'R_MAX' in os.environ else 20 # half size of the box showed for 2D correlation

with open(parameters_file, 'rb') as param_file:
	N, a, pdi, N_sizes, density, box_size, kT, mu, k, vzero, dr, damp_bro, shear_rate, time_step, N_steps, period_dump, prep_steps = pickle.load(param_file)

r_cut = a*float(eval(os.environ['R_CUT'])) if 'R_CUT' in os.environ else a*2 # cutoff radius for coarse graining function
sigma = float(eval(os.environ['SIGMA'])) if 'SIGMA' in os.environ else r_cut # length scale of the spatial extent of the coarse graining function

r_max = box_size/2 if r_max < 0 else r_max

prep_frames = math.ceil(prep_steps/period_dump) # number of preparation frames

Ncases = int(eval(os.environ['N_CASES'])) if 'N_CASES' in os.environ else int(np.sqrt(N)) + (1 - int(np.sqrt(N))%2) # number of cases in each direction to compute the strain and vorticity grid
grid_points = np.array([(x, y) for x in np.linspace(- box_size/2, box_size/2, Ncases, endpoint=False) for y in np.linspace(- box_size/2, box_size/2, Ncases, endpoint=False)])

Nentries = N_steps//period_dump # number of time snapshots in velocity and position files
init_frame = int(Nentries/2) if init_frame < 0 else init_frame # initial frame
Nframes = Nentries - init_frame # number of frames available for the calculation

dis_time = Nframes + dis_time if dis_time <= 0 else dis_time # length of the interval of time for which the correlation displacement is calculated

times = np.array(list(OrderedDict.fromkeys(map(lambda x: int(x), np.linspace(init_frame, Nentries - dis_time - 1, int_max))))) # frames at which to calculate the correlation displacement

def CGf(r, sigma):
	# coarse graining function
	Dg = 2*np.pi*(sigma**2)*(1 - np.exp(-0.5*((r_cut/sigma)**2))) # normalisation factor
	return np.exp(-0.5*((r/sigma)**2))/Dg

def CGfp(positions, sigma):
	# coarse graining factors
	return np.array(list(map(lambda position: CGf(np.sqrt(np.sum(position**2)), sigma), positions)))

def Averaging(var, CGfactors):
	# averages the particle dependent variable var with coarse
	# graining factors
	return np.sum(var*CGfactors)

def strain_vorticity(point, time, dis_time, prep_frames, w_traj, unwrap_file, sigma, r_cut):
	# returns strain and vorticity at point point

	positions = (w_traj[int(prep_frames + time + (dis_time if 'ENDPOINT' in os.environ and eval(os.environ['ENDPOINT']) else 0))].particles.position[:, :2] - point + box_size/2)%box_size - box_size/2 # position at time time (with boundary conditions) with point as the centre of the frame

	pos0 = getarray(unwrap_file, N, time) # positions at time time (without periodic boundary conditions)
	pos1 = getarray(unwrap_file, N, time + dis_time) # position at time time + dis_time (without periodic boundary conditions)
	displacements = pos1 - pos0 # displacements of the particles between time and time + dis_time

	wrcut = np.where(np.sqrt(np.sum(positions**2, axis=1)) < r_cut)[0] # particles indexes within r_cut of point
	if wrcut.size == 0: # there is no particles within r_cut of point
		return 0, 0

	pos_wrcut = np.array(operator.itemgetter(*wrcut)(positions), ndmin=2)
	dis_wrcut = np.array(operator.itemgetter(*wrcut)(displacements), ndmin=2)

	CGfactors = CGfp(pos_wrcut, sigma) # coarse graining factors
	rho, Ax, Auy, Ay, Aux, Auxy, Auyx = tuple(map(lambda var: Averaging(var, CGfactors), [np.full(len(pos_wrcut), fill_value=1), pos_wrcut[:, 0], dis_wrcut[:, 1], pos_wrcut[:, 1], dis_wrcut[:, 0], dis_wrcut[:, 0]*pos_wrcut[:, 1], dis_wrcut[:, 1]*pos_wrcut[:, 0]]))

	strain = 0.5*((Ay*Aux + Ax*Auy)/((rho*sigma)**2) - (Auxy + Auyx)/(rho*(sigma**2)))
	vorticity = (Ax*Auy - Ay*Aux)/((rho*sigma)**2) - (Auyx - Auxy)/(rho*(sigma**2))

	return strain, vorticity

def strain_vorticity_grid(Ncases, grid_points, time, dis_time, prep_frames, w_traj, unwrap_file, sigma, r_cut):
	# returns strain and vorticity Ncases x Ncases grid associated to the box

	Sgrid, Cgrid = tuple(np.transpose(list(map(lambda point: strain_vorticity(point, time, dis_time, prep_frames, w_traj, unwrap_file, sigma, r_cut), grid_points))))

	correct_grid = lambda Grid: np.transpose(np.reshape(Grid, (Ncases, Ncases)))[::-1] # get grid in the correct directions
	return correct_grid(Sgrid), correct_grid(Cgrid)

def corField(field):
	# Return 2D correlation of a scalar field.

	FFT = np.fft.fft2(field)
	C = np.real(np.fft.ifft2(np.conj(FFT)*FFT))
	Norm = np.sum(field**2)

	return C, Norm

with gsd.pygsd.GSDFile(open(wrap_file_name, 'rb')) as wrap_file, open(unwrap_file_name, 'rb') as unwrap_file:
	w_traj = gsd.hoomd.HOOMDTrajectory(wrap_file);
	Sgrid, Cgrid = tuple(np.transpose(list(map(lambda time: strain_vorticity_grid(Ncases, grid_points, time, dis_time, prep_frames, w_traj, unwrap_file, sigma, r_cut), times)), (1, 0, 2, 3)))

Css2D, Ccc2D = tuple(list(map(lambda Grid: (lambda C, Norm: C/Norm)(*tuple(np.sum(list(map(corField, Grid)), axis=0))), [Sgrid, Cgrid]))) # strain and vorticity fields correlations

# SAVING

filename = lambda var: data_dir + str('/' + var + ('b' if not('ENDPOINT' in os.environ and eval(os.environ['ENDPOINT'])) else '') + '_D%s_V%s_R%s_N%s_I%s_T%s_M%s_C%s_RCUT%s_SIGM%s.pickle' % tuple(map(float_to_letters, [density, vzero, dr, N, init_frame, dis_time, int_max, Ncases, r_cut, sigma]))) # filename

with open(filename('Css'), 'wb') as Css_dump_file, open(filename('Ccc'), 'wb') as Ccc_dump_file:
	pickle.dump([Sgrid, Css2D], Css_dump_file)
	pickle.dump([Cgrid, Ccc2D], Ccc_dump_file)

# EXECUTION TIME

print("Execution time: %s" % (datetime.now() - startTime))

# PLOT

if 'SHOW' in os.environ and eval(os.environ['SHOW']):

	import matplotlib as mpl
	import matplotlib.pyplot as plt
	import matplotlib.colors as colors
	import matplotlib.cm as cmx
	from mpl_toolkits.axes_grid1 import make_axes_locatable
	from matplotlib.gridspec import GridSpec
	cmap = plt.cm.jet

	def plot(Grid, Corr, var):

		fig, ax = plt.subplots(1, 2)

		fig.set_size_inches(16, 16)
		fig.subplots_adjust(wspace=0.4)
		fig.subplots_adjust(hspace=0.3)

		fig.suptitle(r'$N=%.2e, \phi=%1.2f, \tilde{v}=%.2e, \tilde{\nu}_r=%.2e$' % (N, density, vzero, dr) + '\n' + r'$S_{init}=%.2e, \Delta t=%.2e, S_{max}=%.2e, N_{cases}=%.2e, r_{cut}=%.2e, \sigma=%.2e$' % (init_frame, dis_time*period_dump*time_step, int_max, Ncases, r_cut, sigma))

		# variable map

		S2D = Grid[0]

		Smin = -2*np.std(S2D)
		Smax = 2*np.std(S2D)

		SvNorm = colors.Normalize(vmin=Smin, vmax=Smax)
		SscalarMap = cmx.ScalarMappable(norm=SvNorm, cmap=cmap)

		ax[0].imshow(S2D, cmap=cmap, norm=SvNorm, extent=[-box_size/2, box_size/2, -box_size/2, box_size/2])

		ax[0].set_xlabel(r'$x$')
		ax[0].set_ylabel(r'$y$')
		ax[0].set_title('2D ' + r'$%s$' % var)

		divider0 = make_axes_locatable(ax[0])
		cax0 = divider0.append_axes("right", size="5%", pad=0.05)
		cb0 = mpl.colorbar.ColorbarBase(cax0, cmap=cmap, norm=SvNorm, orientation='vertical')
		cb0.set_label(r'$%s$' % var, labelpad=20, rotation=270)

		# 2D correlations

		C = 'C_{%s%s}' % (var, var)

		Cmin = np.min(Corr)
		Cmax = np.max(Corr)

		CvNorm = colors.Normalize(vmin=Cmin, vmax=Cmax)
		CscalarMap = cmx.ScalarMappable(norm=CvNorm, cmap=cmap)

		r_max_cases = int(r_max*(Ncases/box_size))
		C2D_display = np.roll(np.roll(Corr, int(Ncases/2), axis=0), int(Ncases/2), axis=1)[int(Ncases/2) - r_max_cases:int(Ncases/2) + r_max_cases + 1, int(Ncases/2) - r_max_cases:int(Ncases/2) + r_max_cases + 1]

		ax[1].imshow(C2D_display, cmap=cmap, norm=CvNorm, extent=[-r_max, r_max, -r_max, r_max])

		ax[1].set_xlabel(r'$x$')
		ax[1].set_ylabel(r'$y$')
		ax[1].set_title('2D ' + r'$%s$' % C)

		divider1 = make_axes_locatable(ax[1])
		cax1 = divider1.append_axes("right", size="5%", pad=0.05)
		cb1 = mpl.colorbar.ColorbarBase(cax1, cmap=cmap, norm=CvNorm, orientation='vertical')
		cb1.set_label(r'$%s$' % C, labelpad=20, rotation=270)

	plot(Sgrid, Css2D, '\epsilon_{xy}')
	plot(Cgrid, Ccc2D, '\omega')

	plt.show()
