#! /home/yketa/miniconda3/bin/python3.6

import os
import sys

import math

import numpy as np

import pickle

sys.path.append('/home/yketa/hoomd/colmig_DPD_P_A/data')
from readdat import *

time = int(eval(os.environ['TIME'])) if 'TIME' in os.environ else -1 # frame for which we calculate the velocity auto-correlation

data_dir = os.environ['DATA_DIRECTORY'] if 'DATA_DIRECTORY' in os.environ else os.getcwd() # data directory

wrap_file_name = os.environ['WRAPPED_FILE'] if 'WRAPPED_FILE' in os.environ else data_dir + '/trajectory.gsd' # wrapped trajectory file (.gsd)
unwrap_file_name = os.environ['UNWRAPPED_FILE'] if 'UNWRAPPED_FILE' in os.environ else data_dir + '/trajectory.dat' # unwrapped trajectory file (binary)
parameters_file = os.environ['PARAMETERS_FILE'] if 'PARAMETERS_FILE' in os.environ else 'param.pickle' # parameters file

with open(parameters_file, 'rb') as param_file:
	N, a, pdi, N_sizes, density, box_size, kT, mu, k, vzero, dr, damp_bro, shear_rate, time_step, N_steps, period_dump, prep_steps = pickle.load(param_file)

time = time if time >= 0 else N_steps//period_dump + time

Ncases = int(eval(os.environ['N_CASES'])) if 'N_CASES' in os.environ else int(np.sqrt(N)) + (1 - int(np.sqrt(N))%2) # number of cases in each direction to compute the velocity grid

def velocity_grid(Ncases, N, L, time, prep_frames, wrap_file, unwrap_file):
	# This function associates a Ncases x Ncases to the box and calculates the average
	# velocity in every cases.

	dL = L/Ncases

	w_traj = gsd.hoomd.HOOMDTrajectory(wrap_file);
	positions = w_traj[int(prep_frames + time)].particles.position[:, :2] # positions of the particles at time time
	velocities = getarray(unwrap_file, N, time, variable='velocity') # velocities of the particles at time time

	index = np.array((pos + L/2)//dL, dtype=int) # 2D index of every particles

	vgrid_dic = {}
	for particle in range(N):
		vgrid_dic[tuple(index[particle])] = vgrid_dic[tuple(index[particle])] + [velocities[particle]] if index in vgrid_dic else [velocities[particle]]

	vgrid = np.zeros((Ncases, Ncases, 2))
	for index in vgrid_dic:
		vgrid[index] = np.mean(vgrid_dic[index], axis=0)

	return vgrid

with gsd.pygsd.GSDFile(open(wrap_file_name, 'rb')) as wrap_file, open(unwrap_file_name, 'rb') as unwrap_file:
	vgrid = velocity_grid(Ncases, N, box_size, prep_frames, wrap_file, unwrap_file) # velocity grid

FFTvgrid = np.fft.fft2(vgrid, axes=(-3, -2))
FFTvxgrid = FFTvgrid[:, :, 0]
FFTvygrid = FFTvgrid[:, :, 1]
Cvv2D = (np.real(np.fft.ifft2(np.conj(FFTvxgrid)*FFTvxgrid)) + np.real(np.fft.ifft2(np.conj(FFTvygrid)*FFTvygrid)))/((Ncases**2) * np.sum(np.mean(vgrid**2, axis=(0,1)))) # velocity auto-correlation

Cvv1D_dic = {}
for i in range(Cvv2D.shape[0]):
	for j in range(Cvv2D.shape[1]):
		if (i**2 + j**2) <= (Ncases/2)**2:
			Cvv1D_dic[int(i**2 + j**2)] = Cvv1D_dic[int(i**2 + j**2)] + [Cvv2D[i, j]] if int(i**2 + j**2) in Cvv1D_dic else [Cvv2D[i, j]]
Cvv1D = np.array(list(map(lambda dist: [np.sqrt(dist)*(box_size/Ncases), np.mean(Cvv1D_dic[dist])], sorted(Cvv1D_dic))))

# PLOT

import matplotlib as mpl
import matplotlib.pyplot as plt
import matplotlib.colors as colors
import matplotlib.cm as cmx
from mpl_toolkits.axes_grid1 import make_axes_locatable

cmap = plt.cm.jet

Cvvmin = 0
Cvvmax = np.max(Cvv2D)

fig, axs = plt.subplots(1, 2)
vNorm = colors.Normalize(vmin=Cvvmin, vmax=Cvvmax)
scalarMap = cmx.ScalarMappable(norm=vNorm, cmap=cmap) 

axs[0].imshow(np.roll(np.roll(Cvv2D, int(Ncases/2), axis=0), int(Ncases/2), axis=1), cmap=cmap, norm=vNorm)

axs[0].set_xlabel('x')
axs[0].set_ylabel('y')
axs[0].set_title('2D C_vv')

divider = make_axes_locatable(axs[0])
cax = divider.append_axes("right", size="5%", pad=0.05)
cb = mpl.colorbar.ColorbarBase(cax, cmap=cmap, norm=vNorm, orientation='vertical')

axs[1].semilogy(Cvv1D[:, 0], Cvv1D[:, 1])

axs[1].set_xlabel('r')
axs[1].set_ylabel('C_vv')
axs[1].set_title('radial C_vv')

fig.subplots_adjust(wspace=0.6)

plt.show()
